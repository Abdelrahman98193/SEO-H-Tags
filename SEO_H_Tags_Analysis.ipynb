{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def count_headings(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        headings_count = {}\n",
        "        for heading_level in range(1, 7):\n",
        "            headings = soup.find_all(f'h{heading_level}')\n",
        "            headings_count[f'H{heading_level}'] = len(headings)\n",
        "\n",
        "        return headings_count, soup\n",
        "    else:\n",
        "        print('Failed to fetch the URL. Please check the provided URL.')\n",
        "        return None, None\n",
        "\n",
        "def write_to_csv(headings_count, soup):\n",
        "    with open('headings_analysis.csv', 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['Heading', 'Type', 'Count'])\n",
        "\n",
        "        for level, count in headings_count.items():\n",
        "            if count > 0:\n",
        "                headings = soup.find_all(level.lower())\n",
        "                for index, heading in enumerate(headings, start=1):\n",
        "                    writer.writerow([heading.text.strip(), level, index])\n",
        "\n",
        "        writer.writerow(['Total Count of Each Heading Type'])\n",
        "        for level, total_count in headings_count.items():\n",
        "            writer.writerow([level, total_count])\n",
        "\n",
        "# Input URL for testing\n",
        "url = input('Enter the URL to analyze: ')\n",
        "headings_count, soup = count_headings(url)\n",
        "\n",
        "if headings_count and soup:\n",
        "    write_to_csv(headings_count, soup)\n",
        "    print('CSV file generated successfully.')"
      ],
      "metadata": {
        "id": "yfucqa4v-Z9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}